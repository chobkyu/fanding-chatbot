# langgraph ê¸°ë°˜ ìƒíƒœ ê¸°ì–µ Agent
from langgraph.graph import StateGraph, END
from langchain_core.runnables import RunnableLambda
from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.chat_models import ChatOpenAI
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain.prompts import ChatPromptTemplate

# ì „ì—­ ìƒíƒœ ì €ìž¥ìš© (ê°„ë‹¨ êµ¬í˜„)
chat_history = []

# ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ì •ì˜ (ê¸°ì¡´ tools ê·¸ëŒ€ë¡œ ì‚¬ìš©)
from tools import search_tool
from main import retriver_tool
tools = [retriver_tool, search_tool]

# í”„ë¡¬í”„íŠ¸
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ íŒ¬ë”© ê³ ê°ì„¼í„° AI ì±—ë´‡ìž…ë‹ˆë‹¤. ê³ ê°ì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”."),
    ("user", "{input}"),
    ("ai", "{agent_scratchpad}")
])

# LLM + Agent ìƒì„±
llm = ChatOpenAI(model="gpt-4", temperature=0.7)
agent_custom = create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)

# AgentExecutor
executor = AgentExecutor(
    agent=agent_custom, 
    tools=tools, 
    verbose=True,
)

# LangGraphìš© ìƒíƒœ ì •ì˜
from typing import TypedDict, List, Union

class AgentState(TypedDict):
    input: str
    chat_history: List[Union[HumanMessage, AIMessage]]

# LangGraphì—ì„œ ì‹¤í–‰í•  í•¨ìˆ˜
def run_agent_with_history(state: AgentState) -> AgentState:
    result = executor.invoke({
        "input": state["input"],
        "chat_history": state["chat_history"]
    })

    # ížˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    new_history = state["chat_history"] + [
        HumanMessage(content=state["input"]),
        AIMessage(content=result["output"])
    ]

    return {
        "input": "",
        "chat_history": new_history,
        "output": result["output"]
    }

# LangGraph êµ¬ì„±
graph = StateGraph(AgentState)
graph.add_node("agent", RunnableLambda(run_agent_with_history))
graph.set_entry_point("agent")
graph.set_finish_point("agent")

# ì»´íŒŒì¼
app = graph.compile()

# ðŸ‘‰ í•¨ìˆ˜ì²˜ëŸ¼ ì“°ëŠ” ëž˜í¼
def get_agent_answer_graph(query: str) -> str:
    global chat_history

    state = {
        "input": query,
        "chat_history": chat_history
    }

    result = app.invoke(state)
    print(result)
    chat_history = result["chat_history"]
    return result["chat_history"][-1].content
